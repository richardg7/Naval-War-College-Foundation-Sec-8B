# Naval-War-College-Foundation-Sec-8B

# Convers√£o de Modelo LLaMA (Meta) da Hugging Face para Ollama

Este reposit√≥rio cont√©m um script Python para convers√£o otimizada de modelos LLaMA (Meta) hospedados na Hugging Face para uso local com suporte a ambientes de GPU limitados e compatibilidade com o Ollama.

## üìå Vis√£o Geral

O script `egn.py` permite:

- Carregamento seguro do modelo Hugging Face com suporte a `float16`
- Otimiza√ß√£o para placas com 6GB de VRAM (ex: RTX 2060)
- Salvamento em shards (`max_shard_size`) compat√≠veis com modelos grandes
- Convers√£o com seguran√ßa de mem√≥ria e offload autom√°tico
- Gera√ß√£o de estrutura final compat√≠vel para uso com o [Ollama](https://ollama.com)

## üß∞ Requisitos

- Python 3.10 ou superior
- GPU com suporte CUDA (m√≠nimo recomendado: 6GB VRAM)
- Depend√™ncias:
  ```bash
  pip install torch transformers psutil
  ```
  ou
  ```bash
    pip install transformers
  ```

> üí° Sugest√£o: `pip install bitsandbytes` para quantiza√ß√£o alternativa em 8-bit.

## üîß Como Utilizar

1. Coloque seu modelo original (Hugging Face) no caminho especificado por `MODEL_PATH`.
2. Execute o script:

   ```bash
   python egn.py
   ```

3. O modelo convertido ser√° salvo na pasta definida como `OUTPUT_PATH`.

4. Para uso com o Ollama, compacte a pasta de sa√≠da:

   ```bash
   tar -czvf Escola-de-Guerra-Naval.tar.gz Escola-de-Guerra-Naval
   ```

## ‚öôÔ∏è Configura√ß√µes Principais

- `MODEL_PATH`: Caminho para o modelo original Hugging Face (ex: `./Foundation-Sec-8B`)
- `OUTPUT_PATH`: Caminho de sa√≠da para o modelo convertido
- `SHARD_SIZE`: Tamanho m√°ximo de cada shard (`500MB` por padr√£o)
- `MAX_MEMORY`: Aloca√ß√£o m√°xima por GPU (`5GB` por padr√£o)

## üö® Solu√ß√£o de Problemas

Caso ocorra erro de mem√≥ria insuficiente:

- Reduza `SHARD_SIZE` para `'250MB'`
- Aumente a VRAM dispon√≠vel ou utilize `bitsandbytes` com quantiza√ß√£o 8-bit
- Utilize offload de par√¢metros com `offload_folder` configurado
- Libere a GPU com `torch.cuda.empty_cache()` antes da execu√ß√£o

---

## üìú Licen√ßa

```text
                                 Apache License
                           Version 2.0, January 2004
                        http://www.apache.org/licenses/

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
```

---

## ‚úçÔ∏è Autor

[Richard Guedes](https://www.linkedin.com/in/richard-guedes/)
Este script foi desenvolvido com foco em desempenho, compatibilidade e acessibilidade para pesquisadores e profissionais que desejam experimentar modelos LLaMA localmente com recursos limitados.
